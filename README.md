# Medical Questions Answering üè•

RAG-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º fine-tuned BERT, –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ LLM. –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω full-stack pipeline: LangGraph multi-step reasoning, structured output (Pydantic), prompt engineering, A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤.

## üéØ –ü—Ä–æ–±–ª–µ–º–∞

–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –≤ –±–æ–ª—å—à–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∑–∞–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. –ü—Ä–æ—Å—Ç–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —á–∞—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

## üí° –†–µ—à–µ–Ω–∏–µ

1. **Retrieval** ‚Äî FAISS –Ω–∞—Ö–æ–¥–∏—Ç —Ç–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ vector search (sentence-transformers)
2. **Reranking** ‚Äî Fine-tuned BERT –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –ø–æ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
3. **LangGraph pipeline** ‚Äî Query Analysis ‚Üí Retrieval ‚Üí Reranking ‚Üí Answer Generation ‚Üí Quality Check
4. **Generation** ‚Äî LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å structured output (Pydantic)
5. **Quality Check** ‚Äî –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –≤–∏–∑–∏—Ç–∞ –∫ –≤—Ä–∞—á—É


**Datasets**
- [curaihealth/medical_questions_pairs](https://huggingface.co/datasets/curaihealth/medical_questions_pairs)
- [ruslanmv/ai-medical-chatbot](https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot)


## ‚ú® –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

| –§–∏—á–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|------|----------|
| **Structured Output** | –°—Ö–µ–º–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ Pydantic: `answer`, `confidence`, `sources`, `requires_doctor_visit`, `warnings` |
| **LangGraph** | Multi-step reasoning: –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ ‚Üí retrieval ‚Üí reranking ‚Üí generation ‚Üí validation |
| **Prompt Engineering** | System guidelines + few-shot examples + chain-of-thought |
| **A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** | –¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä, ROUGE/BLEU, semantic similarity, human feedback –≤ –±–æ—Ç–µ |

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã (–ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ä–µ–∑—é–º–µ)

- **A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤**: –±–∞–∑–æ–≤—ã–π vs few-shot vs CoT vs full. Best ROUGE-L ~0.68 (full).
- **Latency**: <2 —Å–µ–∫ –Ω–∞ CPU (—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π inference).

## üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- **Fine-tuning**: BERT-base
- **Retrieval**: FAISS, sentence-transformers (paraphrase-MiniLM-L3-v2)
- **LLM**: LM Studio (–ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏)
- **Orchestration**: LangGraph, LangChain
- **Structured Output**: Pydantic
- **Evaluation**: rouge-score, BLEU, semantic similarity
- **MLOps**: Weights & Biases
- **API**: FastAPI
- **Deployment**: Docker, Telegram Bot (Aiogram)

## üöÄ –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç

1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Telegram
2. **Query Analysis** ‚Äî –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞, –¥–µ—Ç–µ–∫—Ü–∏—è —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
3. **Retrieval** ‚Äî FAISS –∏—â–µ—Ç top-5 –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
4. **Reranking** ‚Äî BERT –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º top-3
5. **Generation** ‚Äî LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –≤ JSON (structured output)
6. **Quality Check** ‚Äî –ø—Ä–∏ confidence < 0.7 –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
7. –û—Ç–≤–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Å –∫–Ω–æ–ø–∫–∞–º–∏ ¬´–ü–æ–ª–µ–∑–Ω–æ¬ª / ¬´–ù–µ –ø–æ–ª–µ–∑–Ω–æ¬ª (human feedback)

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
‚îú‚îÄ‚îÄ src/api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI: /answer, /feedback
‚îÇ   ‚îú‚îÄ‚îÄ graph.py         # LangGraph pipeline
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py       # Pydantic: MedicalAnswer, Query
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py       # System prompt, few-shot, CoT
‚îÇ   ‚îú‚îÄ‚îÄ llm_generation.py # Structured output generation
‚îÇ   ‚îú‚îÄ‚îÄ retrieval.py     # FAISS + sentence-transformers
‚îÇ   ‚îú‚îÄ‚îÄ models.py        # BERT reranker (SimilarityModel)
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py       # MedicalDataset, train_test, tokenize
‚îÇ   ‚îú‚îÄ‚îÄ train.py         # –û–±—É—á–µ–Ω–∏–µ BERT reranker
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py    # ROUGE, BLEU, semantic similarity
‚îÇ   ‚îî‚îÄ‚îÄ feedback_store.py
‚îú‚îÄ‚îÄ src/bot/main.py      # Telegram bot —Å –∫–Ω–æ–ø–∫–∞–º–∏ feedback
‚îú‚îÄ‚îÄ data/test_questions.json  # –¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–ª—è A/B
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ ab_test_prompts.py   # A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
```

## üèÉ –ó–∞–ø—É—Å–∫

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞
poetry install

# –û–±—É—á–µ–Ω–∏–µ BERT reranker (–µ—Å–ª–∏ –µ—â—ë –Ω–µ –æ–±—É—á–µ–Ω)
# –°–º. src/api/train.py ‚Äî —Ç—Ä–µ–±—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å question_1, question_2 (curaihealth/medical_questions_pairs)

# –ó–∞–ø—É—Å–∫ API (—Ç—Ä–µ–±—É–µ—Ç—Å—è LM Studio –Ω–∞ localhost:1234)
HOST=localhost uvicorn src.api.main:app --reload

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
TELEGRAM_TOKEN=xxx python -m src.bot.main

# A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
poetry run python scripts/ab_test_prompts.py
```

## üìà –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

- **–ü—Ä–æ–º–ø—Ç—ã**: `base`, `few_shot`, `cot`, `full` ‚Äî —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç—Å—è –ø–æ ROUGE-L, BLEU, semantic similarity.

## üé¨ Demo
(–í –ø—Ä–æ—Ü–µ—Å—Å–µ)
[Telegram Bot]() | [Video Demo]()
